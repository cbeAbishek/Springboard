<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/.github/workflows/Auto_checkup.yml">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/.github/workflows/Auto_checkup.yml" />
              <option name="originalContent" value="name: Automated Test Suite&#10;&#10;on:&#10;  push:&#10;    branches: [ main, master ]&#10;  pull_request:&#10;    branches: [ main, master ]&#10;  schedule:&#10;    - cron: '0 2 * * *'  # Daily at 2 AM UTC&#10;  workflow_dispatch:&#10;    inputs:&#10;      test_suite:&#10;        description: 'Test Suite to Run'&#10;        required: true&#10;        default: 'all'&#10;        type: choice&#10;        options:&#10;          - all&#10;          - ui&#10;          - api&#10;          - specific&#10;      test_file:&#10;        description: 'Specific Test File (e.g., org.automation.ui.BlazeDemoTests)'&#10;        required: false&#10;        type: string&#10;      test_method:&#10;        description: 'Specific Test Method (e.g., testHomePageTitle)'&#10;        required: false&#10;        type: string&#10;      browser:&#10;        description: 'Browser for UI Tests'&#10;        required: false&#10;        default: 'chrome'&#10;        type: choice&#10;        options:&#10;          - chrome&#10;          - firefox&#10;      generate_reports:&#10;        description: 'Generate Reports'&#10;        required: false&#10;        default: true&#10;        type: boolean&#10;&#10;# Cancel older runs on same ref to save minutes&#10;concurrency:&#10;  group: regression-${{ github.ref }}&#10;  cancel-in-progress: true&#10;&#10;permissions:&#10;  contents: read&#10;  checks: write&#10;  actions: read&#10;  pull-requests: write&#10;&#10;env:&#10;  MAVEN_OPTS: -Xmx2048m -XX:+UseG1GC -Djava.awt.headless=true&#10;  JAVA_VERSION: '17'&#10;  DB_DATABASE: automation_tests&#10;  DB_USER: root&#10;  DB_PASSWORD: rooT@12345&#10;  CI: true&#10;&#10;jobs:&#10;  setup:&#10;    name:  Setup &amp; Configuration&#10;    runs-on: ubuntu-latest&#10;    outputs:&#10;      test-suites: ${{ steps.determine-suites.outputs.suites }}&#10;      timestamp: ${{ steps.timestamp.outputs.timestamp }}&#10;      test-file: ${{ steps.determine-suites.outputs.testfile }}&#10;      test-method: ${{ steps.determine-suites.outputs.testmethod }}&#10;      skip-ci: ${{ steps.check-commit.outputs.skip }}&#10;    steps:&#10;      - name: Checkout Repository&#10;        uses: actions/checkout@v4&#10;        with:&#10;          fetch-depth: 0&#10;&#10;      - name: Check for automation commits&#10;        id: check-commit&#10;        run: |&#10;          if [[ &quot;${{ github.event.head_commit.message }}&quot; =~ ^(automation|auto|ci|build):.* ]]; then&#10;            echo &quot;skip=true&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;Skipping automation commit: ${{ github.event.head_commit.message }}&quot;&#10;          else&#10;            echo &quot;skip=false&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          fi&#10;&#10;      - name: Generate Timestamp&#10;        id: timestamp&#10;        run: echo &quot;timestamp=$(date +'%Y%m%d_%H%M%S')&quot; &gt;&gt; $GITHUB_OUTPUT&#10;&#10;      - name: Determine Test Suites&#10;        id: determine-suites&#10;        run: |&#10;          if [ &quot;${{ github.event.inputs.test_suite }}&quot; == &quot;specific&quot; ]; then&#10;            echo &quot;suites=[\&quot;specific\&quot;]&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testfile=${{ github.event.inputs.test_file }}&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testmethod=${{ github.event.inputs.test_method }}&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          elif [ &quot;${{ github.event.inputs.test_suite }}&quot; == &quot;ui&quot; ]; then&#10;            echo &quot;suites=[\&quot;ui\&quot;]&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testfile=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testmethod=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          elif [ &quot;${{ github.event.inputs.test_suite }}&quot; == &quot;api&quot; ]; then&#10;            echo &quot;suites=[\&quot;api\&quot;]&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testfile=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testmethod=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          else&#10;            echo &quot;suites=[\&quot;ui\&quot;, \&quot;api\&quot;]&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testfile=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testmethod=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          fi&#10;&#10;      - name: Exit if automation commit&#10;        if: steps.check-commit.outputs.skip == 'true'&#10;        run: |&#10;          echo &quot;Skipping CI for automation commit&quot;&#10;          exit 78&#10;&#10;  api-tests:&#10;    name:  API Tests&#10;    needs: setup&#10;    if: needs.setup.outputs.skip-ci != 'true' &amp;&amp; contains(fromJson(needs.setup.outputs.test-suites), 'api')&#10;    runs-on: ubuntu-latest&#10;    timeout-minutes: 30&#10;&#10;    services:&#10;      mysql:&#10;        image: mysql:8.0&#10;        ports: [ &quot;3306:3306&quot; ]&#10;        env:&#10;          MYSQL_ROOT_PASSWORD: ${{ env.DB_PASSWORD }}&#10;          MYSQL_DATABASE: ${{ env.DB_DATABASE }}&#10;        options: &gt;-&#10;          --health-cmd=&quot;mysqladmin ping -h localhost&quot;&#10;          --health-interval=10s&#10;          --health-timeout=5s&#10;          --health-retries=10&#10;&#10;    steps:&#10;      - name: Checkout Repository&#10;        uses: actions/checkout@v4&#10;&#10;      - name: Set up JDK ${{ env.JAVA_VERSION }}&#10;        uses: actions/setup-java@v4&#10;        with:&#10;          java-version: ${{ env.JAVA_VERSION }}&#10;          distribution: 'temurin'&#10;          cache: maven&#10;&#10;      - name: Print Maven &amp; Java versions&#10;        run: |&#10;          java -version&#10;          mvn -v&#10;&#10;      - name: Wait for MySQL&#10;        run: |&#10;          for i in {1..30}; do&#10;            if mysqladmin ping -h&quot;127.0.0.1&quot; -P3306 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; --silent; then&#10;              echo &quot;MySQL is ready!&quot;&#10;              break&#10;            fi&#10;            echo &quot;Waiting for MySQL... ($i/30)&quot;&#10;            sleep 2&#10;          done&#10;&#10;      - name: Initialize Database Schema&#10;        run: |&#10;          mysql -h127.0.0.1 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; -e &quot;&#10;          CREATE DATABASE IF NOT EXISTS ${DB_DATABASE};&#10;          USE ${DB_DATABASE};&#10;          CREATE TABLE IF NOT EXISTS execution_log (&#10;            id INT AUTO_INCREMENT PRIMARY KEY,&#10;            test_name VARCHAR(255),&#10;            status VARCHAR(20),&#10;            test_type VARCHAR(20),&#10;            us_id VARCHAR(50),&#10;            tc_id VARCHAR(255),&#10;            artifact VARCHAR(500),&#10;            screenshot_path VARCHAR(500),&#10;            execution_time DATETIME DEFAULT CURRENT_TIMESTAMP&#10;          );&quot;&#10;&#10;      - name: Create Required Directories&#10;        run: |&#10;          mkdir -p artifacts/api&#10;          mkdir -p artifacts/reports&#10;          mkdir -p target/surefire-reports&#10;          mkdir -p test-output&#10;&#10;      - name:  Cache Maven Dependencies&#10;        uses: actions/cache@v3&#10;        with:&#10;          path: ~/.m2/repository&#10;          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}&#10;          restore-keys: |&#10;            ${{ runner.os }}-maven-&#10;&#10;      - name:  Build Project&#10;        run: mvn clean install -DskipTests&#10;&#10;      - name: ▶️ Run API Tests (Parallel)&#10;        run: |&#10;          mvn test -Dtest=**/*JsonPlaceholderTests.java \&#10;            -DthreadCount=10 \&#10;            -Ddataproviderthreadcount=10 \&#10;            -Dmaven.test.failure.ignore=true&#10;        env:&#10;          DB_URL: jdbc:mysql://127.0.0.1:3306/${{ env.DB_DATABASE }}&#10;          DB_USERNAME: ${{ env.DB_USER }}&#10;          DB_PASSWORD: ${{ env.DB_PASSWORD }}&#10;&#10;      - name:  Upload API Test Reports&#10;        if: always()&#10;        uses: actions/upload-artifact@v4&#10;        with:&#10;          name: api-test-reports&#10;          path: |&#10;            artifacts/api/&#10;            test-output/emailable-report.html&#10;            test-output/index.html&#10;          retention-days: 30&#10;&#10;      - name: Publish JUnit (API)&#10;        if: always()&#10;        uses: dorny/test-reporter@v1&#10;        with:&#10;          name: API Tests&#10;          path: target/surefire-reports/TEST-*JsonPlaceholderTests.xml&#10;          reporter: java-junit&#10;&#10;  ui-tests:&#10;    name:  UI Tests&#10;    needs: setup&#10;    if: needs.setup.outputs.skip-ci != 'true' &amp;&amp; contains(fromJson(needs.setup.outputs.test-suites), 'ui')&#10;    runs-on: ubuntu-latest&#10;    timeout-minutes: 45&#10;&#10;    services:&#10;      mysql:&#10;        image: mysql:8.0&#10;        ports: [ &quot;3306:3306&quot; ]&#10;        env:&#10;          MYSQL_ROOT_PASSWORD: ${{ env.DB_PASSWORD }}&#10;          MYSQL_DATABASE: ${{ env.DB_DATABASE }}&#10;        options: &gt;-&#10;          --health-cmd=&quot;mysqladmin ping -h localhost&quot;&#10;          --health-interval=10s&#10;          --health-timeout=5s&#10;          --health-retries=10&#10;&#10;    strategy:&#10;      matrix:&#10;        browser: [chrome]&#10;      fail-fast: false&#10;&#10;    steps:&#10;      - name: Checkout Repository&#10;        uses: actions/checkout@v4&#10;&#10;      - name: Set up JDK ${{ env.JAVA_VERSION }}&#10;        uses: actions/setup-java@v4&#10;        with:&#10;          java-version: ${{ env.JAVA_VERSION }}&#10;          distribution: 'temurin'&#10;          cache: maven&#10;&#10;      - name: Print Maven &amp; Java versions&#10;        run: |&#10;          java -version&#10;          mvn -v&#10;&#10;      - name: Wait for MySQL&#10;        run: |&#10;          for i in {1..30}; do&#10;            if mysqladmin ping -h&quot;127.0.0.1&quot; -P3306 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; --silent; then&#10;              echo &quot;MySQL is ready!&quot;&#10;              break&#10;            fi&#10;            echo &quot;Waiting for MySQL... ($i/30)&quot;&#10;            sleep 2&#10;          done&#10;&#10;      - name: Initialize Database Schema&#10;        run: |&#10;          mysql -h127.0.0.1 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; -e &quot;&#10;          CREATE DATABASE IF NOT EXISTS ${DB_DATABASE};&#10;          USE ${DB_DATABASE};&#10;          CREATE TABLE IF NOT EXISTS execution_log (&#10;            id INT AUTO_INCREMENT PRIMARY KEY,&#10;            test_name VARCHAR(255),&#10;            status VARCHAR(20),&#10;            test_type VARCHAR(20),&#10;            us_id VARCHAR(50),&#10;            tc_id VARCHAR(255),&#10;            artifact VARCHAR(500),&#10;            screenshot_path VARCHAR(500),&#10;            execution_time DATETIME DEFAULT CURRENT_TIMESTAMP&#10;          );&quot;&#10;&#10;      - name: Setup Chrome&#10;        if: matrix.browser == 'chrome' || github.event.inputs.browser == 'chrome'&#10;        uses: browser-actions/setup-chrome@latest&#10;        with:&#10;          chrome-version: stable&#10;&#10;      - name: Setup Firefox&#10;        if: matrix.browser == 'firefox' || github.event.inputs.browser == 'firefox'&#10;        uses: browser-actions/setup-firefox@latest&#10;        with:&#10;          firefox-version: latest&#10;&#10;      - name: Show Browser Version&#10;        run: |&#10;          google-chrome --version || chrome --version || firefox --version || echo &quot;Browser version check&quot;&#10;&#10;      - name: Configure Git User&#10;        run: |&#10;          git config --global user.name &quot;GitHub Actions Bot&quot;&#10;          git config --global user.email &quot;actions@github.com&quot;&#10;&#10;      - name: Create Required Directories&#10;        run: |&#10;          mkdir -p artifacts/screenshots&#10;          mkdir -p artifacts/reports&#10;          mkdir -p target/surefire-reports&#10;          mkdir -p target/screenshots&#10;          mkdir -p test-output&#10;&#10;      - name: Install Xvfb for Headless Browser&#10;        run: |&#10;          sudo apt-get update&#10;          sudo apt-get install -y xvfb&#10;&#10;      - name: Resolve &amp; Cache Dependencies&#10;        run: mvn -B -q dependency:go-offline&#10;&#10;      - name: Run UI Tests (Headless)&#10;        run: |&#10;          export DISPLAY=:99&#10;          Xvfb :99 -screen 0 1920x1080x24 &amp;&#10;          sleep 3&#10;          &#10;          mvn -B clean test \&#10;            -Dtest=**/*BlazeDemoTests \&#10;            -Dbrowser=${{ matrix.browser }} \&#10;            -Dheadless=true \&#10;            -Dparallel=methods \&#10;            -DthreadCount=6 \&#10;            -Ddataproviderthreadcount=6 \&#10;            -Dmaven.test.failure.ignore=true&#10;        env:&#10;          BROWSER: ${{ matrix.browser }}&#10;          HEADLESS: true&#10;          SCREENSHOT_ON_FAILURE: true&#10;          DB_URL: jdbc:mysql://127.0.0.1:3306/${{ env.DB_DATABASE }}&#10;          DB_USERNAME: ${{ env.DB_USER }}&#10;          DB_PASSWORD: ${{ env.DB_PASSWORD }}&#10;&#10;      - name: Upload UI Test Reports&#10;        if: always()&#10;        uses: actions/upload-artifact@v4&#10;        with:&#10;          name: ui-test-reports-${{ matrix.browser }}&#10;          path: |&#10;            target/surefire-reports/testng-results.xml&#10;            target/surefire-reports/TEST-*.xml&#10;            target/surefire-reports/*.html&#10;            target/surefire-reports/emailable-report.html&#10;            test-output/testng-results.xml&#10;            test-output/emailable-report.html&#10;            test-output/index.html&#10;            artifacts/screenshots/&#10;          retention-days: 30&#10;&#10;      - name: Publish JUnit (UI)&#10;        if: always()&#10;        uses: dorny/test-reporter@v1&#10;        with:&#10;          name: UI Tests - ${{ matrix.browser }}&#10;          path: target/surefire-reports/TEST-*.xml&#10;          reporter: java-junit&#10;          fail-on-error: false&#10;&#10;  specific-test:&#10;    name:  Specific Test&#10;    needs: setup&#10;    if: needs.setup.outputs.skip-ci != 'true' &amp;&amp; contains(fromJson(needs.setup.outputs.test-suites), 'specific')&#10;    runs-on: ubuntu-latest&#10;    timeout-minutes: 30&#10;&#10;    services:&#10;      mysql:&#10;        image: mysql:8.0&#10;        ports: [ &quot;3306:3306&quot; ]&#10;        env:&#10;          MYSQL_ROOT_PASSWORD: ${{ env.DB_PASSWORD }}&#10;          MYSQL_DATABASE: ${{ env.DB_DATABASE }}&#10;        options: &gt;-&#10;          --health-cmd=&quot;mysqladmin ping -h localhost&quot;&#10;          --health-interval=10s&#10;          --health-timeout=5s&#10;          --health-retries=10&#10;&#10;    steps:&#10;      - name: Checkout Repository&#10;        uses: actions/checkout@v4&#10;&#10;      - name: Set up JDK ${{ env.JAVA_VERSION }}&#10;        uses: actions/setup-java@v4&#10;        with:&#10;          java-version: ${{ env.JAVA_VERSION }}&#10;          distribution: 'temurin'&#10;          cache: maven&#10;&#10;      - name: Wait for MySQL&#10;        run: |&#10;          for i in {1..30}; do&#10;            if mysqladmin ping -h&quot;127.0.0.1&quot; -P3306 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; --silent; then&#10;              echo &quot;MySQL is ready!&quot;&#10;              break&#10;            fi&#10;            echo &quot;Waiting for MySQL... ($i/30)&quot;&#10;            sleep 2&#10;          done&#10;&#10;      - name: Initialize Database Schema&#10;        run: |&#10;          mysql -h127.0.0.1 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; -e &quot;&#10;          CREATE DATABASE IF NOT EXISTS ${DB_DATABASE};&#10;          USE ${DB_DATABASE};&#10;          CREATE TABLE IF NOT EXISTS execution_log (&#10;            id INT AUTO_INCREMENT PRIMARY KEY,&#10;            test_name VARCHAR(255),&#10;            status VARCHAR(20),&#10;            test_type VARCHAR(20),&#10;            us_id VARCHAR(50),&#10;            tc_id VARCHAR(255),&#10;            artifact VARCHAR(500),&#10;            screenshot_path VARCHAR(500),&#10;            execution_time DATETIME DEFAULT CURRENT_TIMESTAMP&#10;          );&quot;&#10;&#10;      - name: Setup Chrome (default for specific tests)&#10;        uses: browser-actions/setup-chrome@latest&#10;        with:&#10;          chrome-version: stable&#10;&#10;      - name: Configure Git User&#10;        run: |&#10;          git config --global user.name &quot;GitHub Actions Bot&quot;&#10;          git config --global user.email &quot;actions@github.com&quot;&#10;&#10;      - name: Create Required Directories&#10;        run: |&#10;          mkdir -p artifacts/screenshots&#10;          mkdir -p artifacts/reports&#10;          mkdir -p target/surefire-reports&#10;          mkdir -p test-output&#10;&#10;      - name: Install Xvfb for Headless Browser&#10;        run: |&#10;          sudo apt-get update&#10;          sudo apt-get install -y xvfb&#10;&#10;      - name: Resolve &amp; Cache Dependencies&#10;        run: mvn -B -q dependency:go-offline&#10;&#10;      - name: Run Specific Test&#10;        run: |&#10;          TEST_CLASS=&quot;${{ needs.setup.outputs.test-file }}&quot;&#10;          TEST_METHOD=&quot;${{ needs.setup.outputs.test-method }}&quot;&#10;          &#10;          if [ -z &quot;$TEST_CLASS&quot; ]; then&#10;            echo &quot;Error: No test class specified&quot;&#10;            exit 1&#10;          fi&#10;          &#10;          export DISPLAY=:99&#10;          Xvfb :99 -screen 0 1920x1080x24 &amp;&#10;          sleep 3&#10;          &#10;          if [ -n &quot;$TEST_METHOD&quot; ]; then&#10;            echo &quot;Running specific test method: $TEST_CLASS#$TEST_METHOD&quot;&#10;            mvn -B clean test \&#10;              -Dtest=&quot;$TEST_CLASS#$TEST_METHOD&quot; \&#10;              -Dbrowser=${{ github.event.inputs.browser || 'chrome' }} \&#10;              -Dheadless=true \&#10;              -Dmaven.test.failure.ignore=true&#10;          else&#10;            echo &quot;Running entire test class: $TEST_CLASS&quot;&#10;            mvn -B clean test \&#10;              -Dtest=&quot;$TEST_CLASS&quot; \&#10;              -Dbrowser=${{ github.event.inputs.browser || 'chrome' }} \&#10;              -Dheadless=true \&#10;              -Dmaven.test.failure.ignore=true&#10;          fi&#10;        env:&#10;          BROWSER: ${{ github.event.inputs.browser || 'chrome' }}&#10;          HEADLESS: true&#10;          SCREENSHOT_ON_FAILURE: true&#10;          DB_URL: jdbc:mysql://127.0.0.1:3306/${{ env.DB_DATABASE }}&#10;          DB_USERNAME: ${{ env.DB_USER }}&#10;          DB_PASSWORD: ${{ env.DB_PASSWORD }}&#10;&#10;      - name: Generate Test Reports&#10;        if: always()&#10;        run: |&#10;          echo &quot;Generating Surefire reports...&quot;&#10;          mvn surefire-report:report-only || true&#10;          mvn site -DgenerateReports=false || true&#10;&#10;      - name: Create Report Summary&#10;        if: always()&#10;        run: |&#10;          mkdir -p artifacts/reports&#10;          echo &quot;# Specific Test Report - ${{ needs.setup.outputs.timestamp }}&quot; &gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Test Class:** ${{ needs.setup.outputs.test-file }}&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Test Method:** ${{ needs.setup.outputs.test-method || 'All methods' }}&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Browser:** ${{ github.event.inputs.browser || 'chrome' }}&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Execution Time:** $(date)&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Branch:** ${{ github.ref_name }}&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Commit:** ${{ github.sha }}&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;&#10;      - name: Upload Specific Test Results&#10;        if: always()&#10;        uses: actions/upload-artifact@v4&#10;        with:&#10;          name: specific-test-results-${{ needs.setup.outputs.timestamp }}&#10;          path: |&#10;            target/surefire-reports/&#10;            target/site/&#10;            artifacts/screenshots/&#10;            artifacts/reports/&#10;            test-output/&#10;          retention-days: 30&#10;&#10;  consolidate-reports:&#10;    name:  Consolidate Reports&#10;    needs: [setup, ui-tests, api-tests, specific-test]&#10;    if: always() &amp;&amp; needs.setup.outputs.skip-ci != 'true' &amp;&amp; (needs.ui-tests.result != 'cancelled' || needs.api-tests.result != 'cancelled' || needs.specific-test.result != 'cancelled')&#10;    runs-on: ubuntu-latest&#10;&#10;    steps:&#10;      - name: Checkout Repository&#10;        uses: actions/checkout@v4&#10;&#10;      - name: Download All Test Results&#10;        uses: actions/download-artifact@v4&#10;        with:&#10;          path: all-results/&#10;&#10;      - name: Consolidate Reports&#10;        run: |&#10;          mkdir -p consolidated-reports/{html,xml,json,screenshots}&#10;          &#10;          # Copy HTML reports&#10;          find all-results/ -name &quot;*.html&quot; -exec cp {} consolidated-reports/html/ \; 2&gt;/dev/null || true&#10;          &#10;          # Copy XML reports&#10;          find all-results/ -name &quot;*.xml&quot; -exec cp {} consolidated-reports/xml/ \; 2&gt;/dev/null || true&#10;          &#10;          # Copy JSON reports (API artifacts)&#10;          find all-results/ -name &quot;*.json&quot; -exec cp {} consolidated-reports/json/ \; 2&gt;/dev/null || true&#10;          &#10;          # Copy screenshots&#10;          find all-results/ -type f \( -name &quot;*.png&quot; -o -name &quot;*.jpg&quot; \) -exec cp {} consolidated-reports/screenshots/ \; 2&gt;/dev/null || true&#10;          &#10;          # Create summary report&#10;          cat &gt; consolidated-reports/README.md &lt;&lt; EOF&#10;          # Test Execution Summary - ${{ needs.setup.outputs.timestamp }}&#10;          &#10;          ## Execution Details&#10;          - **Trigger:** ${{ github.event_name }}&#10;          - **Branch:** ${{ github.ref_name }}&#10;          - **Commit:** ${{ github.sha }}&#10;          - **Timestamp:** $(date)&#10;          &#10;          ## Test Results&#10;          - **UI Tests:** ${{ needs.ui-tests.result || 'N/A' }}&#10;          - **API Tests:** ${{ needs.api-tests.result || 'N/A' }}&#10;          - **Specific Test:** ${{ needs.specific-test.result || 'N/A' }}&#10;          &#10;          ## Report Structure&#10;          - \`html/\` - HTML test reports (TestNG, Surefire)&#10;          - \`xml/\` - XML test results (TestNG/JUnit)&#10;          - \`json/\` - JSON test data (API responses)&#10;          - \`screenshots/\` - Test failure screenshots&#10;          &#10;          ## Test Classes&#10;          - **UI Tests:** org.automation.ui.BlazeDemoTests&#10;          - **API Tests:** org.automation.api.JsonPlaceholderTests&#10;          &#10;          ## Access Reports&#10;          1. Download artifacts from GitHub Actions&#10;          2. View TestNG reports in \`html/\` directory&#10;          3. Check screenshots in \`screenshots/\` directory&#10;          EOF&#10;          &#10;          echo &quot;Report consolidation complete!&quot;&#10;          ls -la consolidated-reports/&#10;&#10;      - name: Parse Test Results Summary&#10;        id: parse-results&#10;        run: |&#10;          TOTAL=0&#10;          PASSED=0&#10;          FAILED=0&#10;          SKIPPED=0&#10;          &#10;          for file in $(find all-results -name &quot;testng-results.xml&quot; 2&gt;/dev/null); do&#10;            if [ -f &quot;$file&quot; ]; then&#10;              echo &quot;Parsing: $file&quot;&#10;              TESTS=$(grep -oP 'total=&quot;\K[0-9]+' &quot;$file&quot; | head -1 || echo &quot;0&quot;)&#10;              PASS=$(grep -oP 'passed=&quot;\K[0-9]+' &quot;$file&quot; | head -1 || echo &quot;0&quot;)&#10;              FAIL=$(grep -oP 'failed=&quot;\K[0-9]+' &quot;$file&quot; | head -1 || echo &quot;0&quot;)&#10;              SKIP=$(grep -oP 'skipped=&quot;\K[0-9]+' &quot;$file&quot; | head -1 || echo &quot;0&quot;)&#10;              &#10;              TOTAL=$((TOTAL + TESTS))&#10;              PASSED=$((PASSED + PASS))&#10;              FAILED=$((FAILED + FAIL))&#10;              SKIPPED=$((SKIPPED + SKIP))&#10;            fi&#10;          done&#10;          &#10;          echo &quot;total=$TOTAL&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          echo &quot;passed=$PASSED&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          echo &quot;failed=$FAILED&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          echo &quot;skipped=$SKIPPED&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          &#10;          # Create visual summary&#10;          cat &gt;&gt; consolidated-reports/README.md &lt;&lt; EOF&#10;          &#10;          ## Statistics&#10;          - **Total Tests:** $TOTAL&#10;          - **Passed:** $PASSED ✅&#10;          - **Failed:** $FAILED ❌&#10;          - **Skipped:** $SKIPPED ⏭️&#10;          - **Pass Rate:** $(awk &quot;BEGIN {printf \&quot;%.2f\&quot;, ($PASSED/$TOTAL)*100}&quot;)%&#10;          EOF&#10;&#10;      - name: Upload Consolidated Reports&#10;        uses: actions/upload-artifact@v4&#10;        with:&#10;          name: consolidated-test-reports-${{ needs.setup.outputs.timestamp }}&#10;          path: consolidated-reports/&#10;          retention-days: 90&#10;&#10;      - name: Generate Job Summary&#10;        if: always()&#10;        run: |&#10;          cat &gt;&gt; $GITHUB_STEP_SUMMARY &lt;&lt; EOF&#10;          #  Test Execution Summary&#10;          &#10;          ##  Results&#10;          | Suite | Status | &#10;          |-------|--------|&#10;          | UI Tests | ${{ needs.ui-tests.result || 'N/A' }} |&#10;          | API Tests | ${{ needs.api-tests.result || 'N/A' }} |&#10;          | Specific Test | ${{ needs.specific-test.result || 'N/A' }} |&#10;          &#10;          ##  Statistics&#10;          - **Total Tests:** ${{ steps.parse-results.outputs.total }}&#10;          - **Passed:** ${{ steps.parse-results.outputs.passed }} ✅&#10;          - **Failed:** ${{ steps.parse-results.outputs.failed }} ❌&#10;          - **Skipped:** ${{ steps.parse-results.outputs.skipped }} ⏭️&#10;          &#10;          ##  Artifacts&#10;          - Consolidated reports available in workflow artifacts&#10;          - Timestamp: ${{ needs.setup.outputs.timestamp }}&#10;          EOF&#10;&#10;  notification:&#10;    name:  Notification&#10;    needs: [setup, ui-tests, api-tests, specific-test, consolidate-reports]&#10;    if: always() &amp;&amp; needs.setup.outputs.skip-ci != 'true'&#10;    runs-on: ubuntu-latest&#10;&#10;    steps:&#10;      - name: Notify on Failure&#10;        if: needs.ui-tests.result == 'failure' || needs.api-tests.result == 'failure' || needs.specific-test.result == 'failure'&#10;        run: |&#10;          echo &quot;⚠️ Tests failed! Check the artifacts for detailed reports.&quot;&#10;          echo &quot;━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━&quot;&#10;          echo &quot;UI Tests: ${{ needs.ui-tests.result }}&quot;&#10;          echo &quot;API Tests: ${{ needs.api-tests.result }}&quot;&#10;          echo &quot;Specific Test: ${{ needs.specific-test.result }}&quot;&#10;          echo &quot;━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━&quot;&#10;          echo &quot; Download consolidated reports from artifacts&quot;&#10;          echo &quot; Check screenshots for UI test failures&quot;&#10;&#10;      - name: Notify on Success&#10;        if: (needs.ui-tests.result == 'success' || needs.ui-tests.result == 'skipped') &amp;&amp; (needs.api-tests.result == 'success' || needs.api-tests.result == 'skipped') &amp;&amp; (needs.specific-test.result == 'success' || needs.specific-test.result == 'skipped')&#10;        run: |&#10;          echo &quot;✅ All tests passed successfully!&quot;&#10;          echo &quot;━━━━━━━━━━━━━━━━━━━━━━━��━━━━━━━━━━━━━━━━&quot;&#10;          echo &quot;UI Tests: ${{ needs.ui-tests.result }}&quot;&#10;          echo &quot;API Tests: ${{ needs.api-tests.result }}&quot;&#10;          echo &quot;Specific Test: ${{ needs.specific-test.result }}&quot;&#10;          echo &quot;━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━&quot;&#10;          echo &quot; Consolidated reports generated&quot;&#10;          echo &quot;✨ All test suites completed successfully&quot;&#10;" />
              <option name="updatedContent" value="name: Automated Test Suite&#10;&#10;on:&#10;  push:&#10;    branches: [ main, master ]&#10;  pull_request:&#10;    branches: [ main, master ]&#10;  schedule:&#10;    - cron: '0 2 * * *'  # Daily at 2 AM UTC&#10;  workflow_dispatch:&#10;    inputs:&#10;      test_suite:&#10;        description: 'Test Suite to Run'&#10;        required: true&#10;        default: 'all'&#10;        type: choice&#10;        options:&#10;          - all&#10;          - ui&#10;          - api&#10;          - specific&#10;      test_file:&#10;        description: 'Specific Test File (e.g., org.automation.ui.BlazeDemoTests)'&#10;        required: false&#10;        type: string&#10;      test_method:&#10;        description: 'Specific Test Method (e.g., testHomePageTitle)'&#10;        required: false&#10;        type: string&#10;      browser:&#10;        description: 'Browser for UI Tests'&#10;        required: false&#10;        default: 'chrome'&#10;        type: choice&#10;        options:&#10;          - chrome&#10;          - firefox&#10;      generate_reports:&#10;        description: 'Generate Reports'&#10;        required: false&#10;        default: true&#10;        type: boolean&#10;&#10;# Cancel older runs on same ref to save minutes&#10;concurrency:&#10;  group: regression-${{ github.ref }}&#10;  cancel-in-progress: true&#10;&#10;permissions:&#10;  contents: read&#10;  checks: write&#10;  actions: read&#10;  pull-requests: write&#10;&#10;env:&#10;  MAVEN_OPTS: -Xmx2048m -XX:+UseG1GC -Djava.awt.headless=true&#10;  JAVA_VERSION: '17'&#10;  DB_DATABASE: automation_tests&#10;  DB_USER: root&#10;  DB_PASSWORD: rooT@12345&#10;  CI: true&#10;&#10;jobs:&#10;  setup:&#10;    name:  Setup &amp; Configuration&#10;    runs-on: ubuntu-latest&#10;    outputs:&#10;      test-suites: ${{ steps.determine-suites.outputs.suites }}&#10;      timestamp: ${{ steps.timestamp.outputs.timestamp }}&#10;      test-file: ${{ steps.determine-suites.outputs.testfile }}&#10;      test-method: ${{ steps.determine-suites.outputs.testmethod }}&#10;      skip-ci: ${{ steps.check-commit.outputs.skip }}&#10;    steps:&#10;      - name: Checkout Repository&#10;        uses: actions/checkout@v4&#10;        with:&#10;          fetch-depth: 0&#10;&#10;      - name: Check for automation commits&#10;        id: check-commit&#10;        run: |&#10;          if [[ &quot;${{ github.event.head_commit.message }}&quot; =~ ^(automation|auto|ci|build):.* ]]; then&#10;            echo &quot;skip=true&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;Skipping automation commit: ${{ github.event.head_commit.message }}&quot;&#10;          else&#10;            echo &quot;skip=false&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          fi&#10;&#10;      - name: Generate Timestamp&#10;        id: timestamp&#10;        run: echo &quot;timestamp=$(date +'%Y%m%d_%H%M%S')&quot; &gt;&gt; $GITHUB_OUTPUT&#10;&#10;      - name: Determine Test Suites&#10;        id: determine-suites&#10;        run: |&#10;          if [ &quot;${{ github.event.inputs.test_suite }}&quot; == &quot;specific&quot; ]; then&#10;            echo &quot;suites=[\&quot;specific\&quot;]&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testfile=${{ github.event.inputs.test_file }}&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testmethod=${{ github.event.inputs.test_method }}&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          elif [ &quot;${{ github.event.inputs.test_suite }}&quot; == &quot;ui&quot; ]; then&#10;            echo &quot;suites=[\&quot;ui\&quot;]&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testfile=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testmethod=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          elif [ &quot;${{ github.event.inputs.test_suite }}&quot; == &quot;api&quot; ]; then&#10;            echo &quot;suites=[\&quot;api\&quot;]&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testfile=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testmethod=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          else&#10;            echo &quot;suites=[\&quot;ui\&quot;, \&quot;api\&quot;]&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testfile=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;            echo &quot;testmethod=&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          fi&#10;&#10;      - name: Exit if automation commit&#10;        if: steps.check-commit.outputs.skip == 'true'&#10;        run: |&#10;          echo &quot;Skipping CI for automation commit&quot;&#10;          exit 78&#10;&#10;  api-tests:&#10;    name:  API Tests&#10;    needs: setup&#10;    if: needs.setup.outputs.skip-ci != 'true' &amp;&amp; contains(fromJson(needs.setup.outputs.test-suites), 'api')&#10;    runs-on: ubuntu-latest&#10;    timeout-minutes: 30&#10;&#10;    services:&#10;      mysql:&#10;        image: mysql:8.0&#10;        ports: [ &quot;3306:3306&quot; ]&#10;        env:&#10;          MYSQL_ROOT_PASSWORD: ${{ env.DB_PASSWORD }}&#10;          MYSQL_DATABASE: ${{ env.DB_DATABASE }}&#10;        options: &gt;-&#10;          --health-cmd=&quot;mysqladmin ping -h localhost&quot;&#10;          --health-interval=10s&#10;          --health-timeout=5s&#10;          --health-retries=10&#10;&#10;    steps:&#10;      - name: Checkout Repository&#10;        uses: actions/checkout@v4&#10;&#10;      - name: Set up JDK ${{ env.JAVA_VERSION }}&#10;        uses: actions/setup-java@v4&#10;        with:&#10;          java-version: ${{ env.JAVA_VERSION }}&#10;          distribution: 'temurin'&#10;          cache: maven&#10;&#10;      - name: Print Maven &amp; Java versions&#10;        run: |&#10;          java -version&#10;          mvn -v&#10;&#10;      - name: Wait for MySQL&#10;        run: |&#10;          for i in {1..30}; do&#10;            if mysqladmin ping -h&quot;127.0.0.1&quot; -P3306 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; --silent; then&#10;              echo &quot;MySQL is ready!&quot;&#10;              break&#10;            fi&#10;            echo &quot;Waiting for MySQL... ($i/30)&quot;&#10;            sleep 2&#10;          done&#10;&#10;      - name: Initialize Database Schema&#10;        run: |&#10;          mysql -h127.0.0.1 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; -e &quot;&#10;          CREATE DATABASE IF NOT EXISTS ${DB_DATABASE};&#10;          USE ${DB_DATABASE};&#10;          CREATE TABLE IF NOT EXISTS execution_log (&#10;            id INT AUTO_INCREMENT PRIMARY KEY,&#10;            test_name VARCHAR(255),&#10;            status VARCHAR(20),&#10;            test_type VARCHAR(20),&#10;            us_id VARCHAR(50),&#10;            tc_id VARCHAR(255),&#10;            artifact VARCHAR(500),&#10;            screenshot_path VARCHAR(500),&#10;            execution_time DATETIME DEFAULT CURRENT_TIMESTAMP&#10;          );&quot;&#10;&#10;      - name: Create Required Directories&#10;        run: |&#10;          mkdir -p artifacts/api&#10;          mkdir -p artifacts/reports&#10;          mkdir -p target/surefire-reports&#10;          mkdir -p test-output&#10;&#10;      - name:  Cache Maven Dependencies&#10;        uses: actions/cache@v3&#10;        with:&#10;          path: ~/.m2/repository&#10;          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}&#10;          restore-keys: |&#10;            ${{ runner.os }}-maven-&#10;&#10;      - name:  Build Project&#10;        run: mvn clean install -DskipTests&#10;&#10;      - name: ▶️ Run API Tests (Parallel)&#10;        run: |&#10;          mvn test -Dtest=**/*JsonPlaceholderTests.java \&#10;            -DthreadCount=10 \&#10;            -Ddataproviderthreadcount=10 \&#10;            -Dmaven.test.failure.ignore=true&#10;        env:&#10;          DB_URL: jdbc:mysql://127.0.0.1:3306/${{ env.DB_DATABASE }}&#10;          DB_USERNAME: ${{ env.DB_USER }}&#10;          DB_PASSWORD: ${{ env.DB_PASSWORD }}&#10;&#10;      - name:  Upload API Test Reports&#10;        if: always()&#10;        uses: actions/upload-artifact@v4&#10;        with:&#10;          name: api-test-reports&#10;          path: |&#10;            artifacts/api/&#10;            test-output/emailable-report.html&#10;            test-output/index.html&#10;          retention-days: 30&#10;&#10;      - name: Publish JUnit (API)&#10;        if: always()&#10;        uses: dorny/test-reporter@v1&#10;        with:&#10;          name: API Tests&#10;          path: target/surefire-reports/TEST-*JsonPlaceholderTests.xml&#10;          reporter: java-junit&#10;&#10;  ui-tests:&#10;    name:  UI Tests&#10;    needs: setup&#10;    if: needs.setup.outputs.skip-ci != 'true' &amp;&amp; contains(fromJson(needs.setup.outputs.test-suites), 'ui')&#10;    runs-on: ubuntu-latest&#10;    timeout-minutes: 45&#10;&#10;    services:&#10;      mysql:&#10;        image: mysql:8.0&#10;        ports: [ &quot;3306:3306&quot; ]&#10;        env:&#10;          MYSQL_ROOT_PASSWORD: ${{ env.DB_PASSWORD }}&#10;          MYSQL_DATABASE: ${{ env.DB_DATABASE }}&#10;        options: &gt;-&#10;          --health-cmd=&quot;mysqladmin ping -h localhost&quot;&#10;          --health-interval=10s&#10;          --health-timeout=5s&#10;          --health-retries=10&#10;&#10;    strategy:&#10;      matrix:&#10;        browser: [chrome]&#10;      fail-fast: false&#10;&#10;    steps:&#10;      - name: Checkout Repository&#10;        uses: actions/checkout@v4&#10;&#10;      - name: Set up JDK ${{ env.JAVA_VERSION }}&#10;        uses: actions/setup-java@v4&#10;        with:&#10;          java-version: ${{ env.JAVA_VERSION }}&#10;          distribution: 'temurin'&#10;          cache: maven&#10;&#10;      - name: Print Maven &amp; Java versions&#10;        run: |&#10;          java -version&#10;          mvn -v&#10;&#10;      - name: Wait for MySQL&#10;        run: |&#10;          for i in {1..30}; do&#10;            if mysqladmin ping -h&quot;127.0.0.1&quot; -P3306 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; --silent; then&#10;              echo &quot;MySQL is ready!&quot;&#10;              break&#10;            fi&#10;            echo &quot;Waiting for MySQL... ($i/30)&quot;&#10;            sleep 2&#10;          done&#10;&#10;      - name: Initialize Database Schema&#10;        run: |&#10;          mysql -h127.0.0.1 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; -e &quot;&#10;          CREATE DATABASE IF NOT EXISTS ${DB_DATABASE};&#10;          USE ${DB_DATABASE};&#10;          CREATE TABLE IF NOT EXISTS execution_log (&#10;            id INT AUTO_INCREMENT PRIMARY KEY,&#10;            test_name VARCHAR(255),&#10;            status VARCHAR(20),&#10;            test_type VARCHAR(20),&#10;            us_id VARCHAR(50),&#10;            tc_id VARCHAR(255),&#10;            artifact VARCHAR(500),&#10;            screenshot_path VARCHAR(500),&#10;            execution_time DATETIME DEFAULT CURRENT_TIMESTAMP&#10;          );&quot;&#10;&#10;      - name: Setup Chrome&#10;        if: matrix.browser == 'chrome' || github.event.inputs.browser == 'chrome'&#10;        uses: browser-actions/setup-chrome@latest&#10;        with:&#10;          chrome-version: stable&#10;&#10;      - name: Setup Firefox&#10;        if: matrix.browser == 'firefox' || github.event.inputs.browser == 'firefox'&#10;        uses: browser-actions/setup-firefox@latest&#10;        with:&#10;          firefox-version: latest&#10;&#10;      - name: Show Browser Version&#10;        run: |&#10;          google-chrome --version || chrome --version || firefox --version || echo &quot;Browser version check&quot;&#10;&#10;      - name: Configure Git User&#10;        run: |&#10;          git config --global user.name &quot;GitHub Actions Bot&quot;&#10;          git config --global user.email &quot;actions@github.com&quot;&#10;&#10;      - name: Create Required Directories&#10;        run: |&#10;          mkdir -p artifacts/screenshots&#10;          mkdir -p artifacts/reports&#10;          mkdir -p target/surefire-reports&#10;          mkdir -p target/screenshots&#10;          mkdir -p test-output&#10;&#10;      - name: Install Xvfb for Headless Browser&#10;        run: |&#10;          sudo apt-get update&#10;          sudo apt-get install -y xvfb&#10;&#10;      - name: Resolve &amp; Cache Dependencies&#10;        run: mvn -B -q dependency:go-offline&#10;&#10;      - name: Run UI Tests (Headless)&#10;        run: |&#10;          export DISPLAY=:99&#10;          Xvfb :99 -screen 0 1920x1080x24 &amp;&#10;          sleep 3&#10;          &#10;          mvn -B clean test \&#10;            -Dtest=**/*BlazeDemoTests \&#10;            -Dbrowser=${{ matrix.browser }} \&#10;            -Dheadless=true \&#10;            -Dparallel=methods \&#10;            -DthreadCount=6 \&#10;            -Ddataproviderthreadcount=6 \&#10;            -Dmaven.test.failure.ignore=true&#10;        env:&#10;          BROWSER: ${{ matrix.browser }}&#10;          HEADLESS: true&#10;          SCREENSHOT_ON_FAILURE: true&#10;          DB_URL: jdbc:mysql://127.0.0.1:3306/${{ env.DB_DATABASE }}&#10;          DB_USERNAME: ${{ env.DB_USER }}&#10;          DB_PASSWORD: ${{ env.DB_PASSWORD }}&#10;&#10;      - name: Upload UI Test Reports&#10;        if: always()&#10;        uses: actions/upload-artifact@v4&#10;        with:&#10;          name: ui-test-reports-${{ matrix.browser }}&#10;          path: |&#10;            target/surefire-reports/testng-results.xml&#10;            target/surefire-reports/TEST-*.xml&#10;            target/surefire-reports/*.html&#10;            target/surefire-reports/emailable-report.html&#10;            test-output/testng-results.xml&#10;            test-output/emailable-report.html&#10;            test-output/index.html&#10;            artifacts/screenshots/&#10;          retention-days: 30&#10;&#10;      - name: Publish JUnit (UI)&#10;        if: always()&#10;        uses: dorny/test-reporter@v1&#10;        with:&#10;          name: UI Tests - ${{ matrix.browser }}&#10;          path: target/surefire-reports/TEST-*.xml&#10;          reporter: java-junit&#10;          fail-on-error: false&#10;&#10;  specific-test:&#10;    name:  Specific Test&#10;    needs: setup&#10;    if: needs.setup.outputs.skip-ci != 'true' &amp;&amp; contains(fromJson(needs.setup.outputs.test-suites), 'specific')&#10;    runs-on: ubuntu-latest&#10;    timeout-minutes: 30&#10;&#10;    services:&#10;      mysql:&#10;        image: mysql:8.0&#10;        ports: [ &quot;3306:3306&quot; ]&#10;        env:&#10;          MYSQL_ROOT_PASSWORD: ${{ env.DB_PASSWORD }}&#10;          MYSQL_DATABASE: ${{ env.DB_DATABASE }}&#10;        options: &gt;-&#10;          --health-cmd=&quot;mysqladmin ping -h localhost&quot;&#10;          --health-interval=10s&#10;          --health-timeout=5s&#10;          --health-retries=10&#10;&#10;    steps:&#10;      - name: Checkout Repository&#10;        uses: actions/checkout@v4&#10;&#10;      - name: Set up JDK ${{ env.JAVA_VERSION }}&#10;        uses: actions/setup-java@v4&#10;        with:&#10;          java-version: ${{ env.JAVA_VERSION }}&#10;          distribution: 'temurin'&#10;          cache: maven&#10;&#10;      - name: Wait for MySQL&#10;        run: |&#10;          for i in {1..30}; do&#10;            if mysqladmin ping -h&quot;127.0.0.1&quot; -P3306 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; --silent; then&#10;              echo &quot;MySQL is ready!&quot;&#10;              break&#10;            fi&#10;            echo &quot;Waiting for MySQL... ($i/30)&quot;&#10;            sleep 2&#10;          done&#10;&#10;      - name: Initialize Database Schema&#10;        run: |&#10;          mysql -h127.0.0.1 -u${{ env.DB_USER }} -p&quot;${{ env.DB_PASSWORD }}&quot; -e &quot;&#10;          CREATE DATABASE IF NOT EXISTS ${DB_DATABASE};&#10;          USE ${DB_DATABASE};&#10;          CREATE TABLE IF NOT EXISTS execution_log (&#10;            id INT AUTO_INCREMENT PRIMARY KEY,&#10;            test_name VARCHAR(255),&#10;            status VARCHAR(20),&#10;            test_type VARCHAR(20),&#10;            us_id VARCHAR(50),&#10;            tc_id VARCHAR(255),&#10;            artifact VARCHAR(500),&#10;            screenshot_path VARCHAR(500),&#10;            execution_time DATETIME DEFAULT CURRENT_TIMESTAMP&#10;          );&quot;&#10;&#10;      - name: Setup Chrome (default for specific tests)&#10;        uses: browser-actions/setup-chrome@latest&#10;        with:&#10;          chrome-version: stable&#10;&#10;      - name: Configure Git User&#10;        run: |&#10;          git config --global user.name &quot;GitHub Actions Bot&quot;&#10;          git config --global user.email &quot;actions@github.com&quot;&#10;&#10;      - name: Create Required Directories&#10;        run: |&#10;          mkdir -p artifacts/screenshots&#10;          mkdir -p artifacts/reports&#10;          mkdir -p target/surefire-reports&#10;          mkdir -p test-output&#10;&#10;      - name: Install Xvfb for Headless Browser&#10;        run: |&#10;          sudo apt-get update&#10;          sudo apt-get install -y xvfb&#10;&#10;      - name: Resolve &amp; Cache Dependencies&#10;        run: mvn -B -q dependency:go-offline&#10;&#10;      - name: Run Specific Test&#10;        run: |&#10;          TEST_CLASS=&quot;${{ needs.setup.outputs.test-file }}&quot;&#10;          TEST_METHOD=&quot;${{ needs.setup.outputs.test-method }}&quot;&#10;          &#10;          if [ -z &quot;$TEST_CLASS&quot; ]; then&#10;            echo &quot;Error: No test class specified&quot;&#10;            exit 1&#10;          fi&#10;          &#10;          export DISPLAY=:99&#10;          Xvfb :99 -screen 0 1920x1080x24 &amp;&#10;          sleep 3&#10;          &#10;          if [ -n &quot;$TEST_METHOD&quot; ]; then&#10;            echo &quot;Running specific test method: $TEST_CLASS#$TEST_METHOD&quot;&#10;            mvn -B clean test \&#10;              -Dtest=&quot;$TEST_CLASS#$TEST_METHOD&quot; \&#10;              -Dbrowser=${{ github.event.inputs.browser || 'chrome' }} \&#10;              -Dheadless=true \&#10;              -Dmaven.test.failure.ignore=true&#10;          else&#10;            echo &quot;Running entire test class: $TEST_CLASS&quot;&#10;            mvn -B clean test \&#10;              -Dtest=&quot;$TEST_CLASS&quot; \&#10;              -Dbrowser=${{ github.event.inputs.browser || 'chrome' }} \&#10;              -Dheadless=true \&#10;              -Dmaven.test.failure.ignore=true&#10;          fi&#10;        env:&#10;          BROWSER: ${{ github.event.inputs.browser || 'chrome' }}&#10;          HEADLESS: true&#10;          SCREENSHOT_ON_FAILURE: true&#10;          DB_URL: jdbc:mysql://127.0.0.1:3306/${{ env.DB_DATABASE }}&#10;          DB_USERNAME: ${{ env.DB_USER }}&#10;          DB_PASSWORD: ${{ env.DB_PASSWORD }}&#10;&#10;      - name: Generate Test Reports&#10;        if: always()&#10;        run: |&#10;          echo &quot;Generating Surefire reports...&quot;&#10;          mvn surefire-report:report-only || true&#10;          mvn site -DgenerateReports=false || true&#10;&#10;      - name: Create Report Summary&#10;        if: always()&#10;        run: |&#10;          mkdir -p artifacts/reports&#10;          echo &quot;# Specific Test Report - ${{ needs.setup.outputs.timestamp }}&quot; &gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Test Class:** ${{ needs.setup.outputs.test-file }}&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Test Method:** ${{ needs.setup.outputs.test-method || 'All methods' }}&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Browser:** ${{ github.event.inputs.browser || 'chrome' }}&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Execution Time:** $(date)&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Branch:** ${{ github.ref_name }}&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;          echo &quot;**Commit:** ${{ github.sha }}&quot; &gt;&gt; artifacts/reports/specific-test-summary.md&#10;&#10;      - name: Upload Specific Test Results&#10;        if: always()&#10;        uses: actions/upload-artifact@v4&#10;        with:&#10;          name: specific-test-results-${{ needs.setup.outputs.timestamp }}&#10;          path: |&#10;            target/surefire-reports/&#10;            target/site/&#10;            artifacts/screenshots/&#10;            artifacts/reports/&#10;            test-output/&#10;          retention-days: 30&#10;&#10;  consolidate-reports:&#10;    name:  Consolidate Reports&#10;    needs: [setup, ui-tests, api-tests, specific-test]&#10;    if: always() &amp;&amp; needs.setup.outputs.skip-ci != 'true' &amp;&amp; (needs.ui-tests.result != 'cancelled' || needs.api-tests.result != 'cancelled' || needs.specific-test.result != 'cancelled')&#10;    runs-on: ubuntu-latest&#10;&#10;    steps:&#10;      - name: Checkout Repository&#10;        uses: actions/checkout@v4&#10;&#10;      - name: Download All Test Results&#10;        uses: actions/download-artifact@v4&#10;        with:&#10;          path: all-results/&#10;&#10;      - name: Consolidate Reports&#10;        run: |&#10;          mkdir -p consolidated-reports/{html,xml,json,screenshots}&#10;          &#10;          # Copy HTML reports&#10;          find all-results/ -name &quot;*.html&quot; -exec cp {} consolidated-reports/html/ \; 2&gt;/dev/null || true&#10;          &#10;          # Copy XML reports&#10;          find all-results/ -name &quot;*.xml&quot; -exec cp {} consolidated-reports/xml/ \; 2&gt;/dev/null || true&#10;          &#10;          # Copy JSON reports (API artifacts)&#10;          find all-results/ -name &quot;*.json&quot; -exec cp {} consolidated-reports/json/ \; 2&gt;/dev/null || true&#10;          &#10;          # Copy screenshots&#10;          find all-results/ -type f \( -name &quot;*.png&quot; -o -name &quot;*.jpg&quot; \) -exec cp {} consolidated-reports/screenshots/ \; 2&gt;/dev/null || true&#10;          &#10;          # Create summary report&#10;          cat &gt; consolidated-reports/README.md &lt;&lt; EOF&#10;          # Test Execution Summary - ${{ needs.setup.outputs.timestamp }}&#10;          &#10;          ## Execution Details&#10;          - **Trigger:** ${{ github.event_name }}&#10;          - **Branch:** ${{ github.ref_name }}&#10;          - **Commit:** ${{ github.sha }}&#10;          - **Timestamp:** $(date)&#10;          &#10;          ## Test Results&#10;          - **UI Tests:** ${{ needs.ui-tests.result || 'N/A' }}&#10;          - **API Tests:** ${{ needs.api-tests.result || 'N/A' }}&#10;          - **Specific Test:** ${{ needs.specific-test.result || 'N/A' }}&#10;          &#10;          ## Report Structure&#10;          - \`html/\` - HTML test reports (TestNG, Surefire)&#10;          - \`xml/\` - XML test results (TestNG/JUnit)&#10;          - \`json/\` - JSON test data (API responses)&#10;          - \`screenshots/\` - Test failure screenshots&#10;          &#10;          ## Test Classes&#10;          - **UI Tests:** org.automation.ui.BlazeDemoTests&#10;          - **API Tests:** org.automation.api.JsonPlaceholderTests&#10;          &#10;          ## Access Reports&#10;          1. Download artifacts from GitHub Actions&#10;          2. View TestNG reports in \`html/\` directory&#10;          3. Check screenshots in \`screenshots/\` directory&#10;          EOF&#10;          &#10;          echo &quot;Report consolidation complete!&quot;&#10;          ls -la consolidated-reports/&#10;&#10;      - name: Parse Test Results Summary&#10;        id: parse-results&#10;        run: |&#10;          TOTAL=0&#10;          PASSED=0&#10;          FAILED=0&#10;          SKIPPED=0&#10;          &#10;          echo &quot;Searching for testng-results.xml files...&quot;&#10;          find all-results -name &quot;testng-results.xml&quot; -type f 2&gt;/dev/null || echo &quot;No files found yet&quot;&#10;          &#10;          # Parse testng-results.xml files&#10;          for file in $(find all-results -name &quot;testng-results.xml&quot; -type f 2&gt;/dev/null); do&#10;            if [ -f &quot;$file&quot; ]; then&#10;              echo &quot;================================================&quot;&#10;              echo &quot;Parsing: $file&quot;&#10;              cat &quot;$file&quot; | head -5&#10;              &#10;              # Extract test counts from testng-results.xml&#10;              TESTS=$(grep -oP '&lt;testng-results[^&gt;]*total=&quot;\K[0-9]+' &quot;$file&quot; | head -1 || echo &quot;0&quot;)&#10;              PASS=$(grep -oP '&lt;testng-results[^&gt;]*passed=&quot;\K[0-9]+' &quot;$file&quot; | head -1 || echo &quot;0&quot;)&#10;              FAIL=$(grep -oP '&lt;testng-results[^&gt;]*failed=&quot;\K[0-9]+' &quot;$file&quot; | head -1 || echo &quot;0&quot;)&#10;              SKIP=$(grep -oP '&lt;testng-results[^&gt;]*skipped=&quot;\K[0-9]+' &quot;$file&quot; | head -1 || echo &quot;0&quot;)&#10;              &#10;              echo &quot;  Tests: $TESTS, Passed: $PASS, Failed: $FAIL, Skipped: $SKIP&quot;&#10;              &#10;              TOTAL=$((TOTAL + TESTS))&#10;              PASSED=$((PASSED + PASS))&#10;              FAILED=$((FAILED + FAIL))&#10;              SKIPPED=$((SKIPPED + SKIP))&#10;            fi&#10;          done&#10;          &#10;          echo &quot;================================================&quot;&#10;          echo &quot;FINAL TOTALS:&quot;&#10;          echo &quot;  Total: $TOTAL&quot;&#10;          echo &quot;  Passed: $PASSED&quot;&#10;          echo &quot;  Failed: $FAILED&quot;&#10;          echo &quot;  Skipped: $SKIPPED&quot;&#10;          &#10;          echo &quot;total=$TOTAL&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          echo &quot;passed=$PASSED&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          echo &quot;failed=$FAILED&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          echo &quot;skipped=$SKIPPED&quot; &gt;&gt; $GITHUB_OUTPUT&#10;          &#10;          # Calculate pass rate (avoid division by zero)&#10;          if [ $TOTAL -gt 0 ]; then&#10;            PASS_RATE=$(awk &quot;BEGIN {printf \&quot;%.2f\&quot;, ($PASSED/$TOTAL)*100}&quot;)&#10;          else&#10;            PASS_RATE=&quot;0.00&quot;&#10;          fi&#10;          &#10;          # Create visual summary&#10;          cat &gt;&gt; consolidated-reports/README.md &lt;&lt; EOF&#10;          &#10;          ## Statistics&#10;          - **Total Tests:** $TOTAL&#10;          - **Passed:** $PASSED ✅&#10;          - **Failed:** $FAILED ❌&#10;          - **Skipped:** $SKIPPED ⏭️&#10;          - **Pass Rate:** ${PASS_RATE}%&#10;          &#10;          ## Detailed Test Files&#10;          EOF&#10;          &#10;          # List all test result files found&#10;          echo &quot;&quot; &gt;&gt; consolidated-reports/README.md&#10;          echo &quot;### TestNG Result Files:&quot; &gt;&gt; consolidated-reports/README.md&#10;          find all-results -name &quot;testng-results.xml&quot; -type f 2&gt;/dev/null | while read file; do&#10;            echo &quot;- \`$file\`&quot; &gt;&gt; consolidated-reports/README.md&#10;          done&#10;&#10;      - name: Upload Consolidated Reports&#10;        uses: actions/upload-artifact@v4&#10;        with:&#10;          name: consolidated-test-reports-${{ needs.setup.outputs.timestamp }}&#10;          path: consolidated-reports/&#10;          retention-days: 90&#10;&#10;      - name: Generate Job Summary&#10;        if: always()&#10;        run: |&#10;          cat &gt;&gt; $GITHUB_STEP_SUMMARY &lt;&lt; EOF&#10;          #  Test Execution Summary&#10;          &#10;          ##  Results&#10;          | Suite | Status | &#10;          |-------|--------|&#10;          | UI Tests | ${{ needs.ui-tests.result || 'N/A' }} |&#10;          | API Tests | ${{ needs.api-tests.result || 'N/A' }} |&#10;          | Specific Test | ${{ needs.specific-test.result || 'N/A' }} |&#10;          &#10;          ##  Statistics&#10;          - **Total Tests:** ${{ steps.parse-results.outputs.total }}&#10;          - **Passed:** ${{ steps.parse-results.outputs.passed }} ✅&#10;          - **Failed:** ${{ steps.parse-results.outputs.failed }} ❌&#10;          - **Skipped:** ${{ steps.parse-results.outputs.skipped }} ⏭️&#10;          &#10;          ##  Artifacts&#10;          - Consolidated reports available in workflow artifacts&#10;          - Timestamp: ${{ needs.setup.outputs.timestamp }}&#10;          EOF&#10;&#10;  notification:&#10;    name:  Notification&#10;    needs: [setup, ui-tests, api-tests, specific-test, consolidate-reports]&#10;    if: always() &amp;&amp; needs.setup.outputs.skip-ci != 'true'&#10;    runs-on: ubuntu-latest&#10;&#10;    steps:&#10;      - name: Notify on Failure&#10;        if: needs.ui-tests.result == 'failure' || needs.api-tests.result == 'failure' || needs.specific-test.result == 'failure'&#10;        run: |&#10;          echo &quot;⚠️ Tests failed! Check the artifacts for detailed reports.&quot;&#10;          echo &quot;━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━&quot;&#10;          echo &quot;UI Tests: ${{ needs.ui-tests.result }}&quot;&#10;          echo &quot;API Tests: ${{ needs.api-tests.result }}&quot;&#10;          echo &quot;Specific Test: ${{ needs.specific-test.result }}&quot;&#10;          echo &quot;━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━&quot;&#10;          echo &quot; Download consolidated reports from artifacts&quot;&#10;          echo &quot; Check screenshots for UI test failures&quot;&#10;&#10;      - name: Notify on Success&#10;        if: (needs.ui-tests.result == 'success' || needs.ui-tests.result == 'skipped') &amp;&amp; (needs.api-tests.result == 'success' || needs.api-tests.result == 'skipped') &amp;&amp; (needs.specific-test.result == 'success' || needs.specific-test.result == 'skipped')&#10;        run: |&#10;          echo &quot;✅ All tests passed successfully!&quot;&#10;          echo &quot;━━━━━━━━━━━━━━━━━━━━━━━��━━━━━━━━━━━━━━━━&quot;&#10;          echo &quot;UI Tests: ${{ needs.ui-tests.result }}&quot;&#10;          echo &quot;API Tests: ${{ needs.api-tests.result }}&quot;&#10;          echo &quot;Specific Test: ${{ needs.specific-test.result }}&quot;&#10;          echo &quot;━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━&quot;&#10;          echo &quot; Consolidated reports generated&quot;&#10;          echo &quot;✨ All test suites completed successfully&quot;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>