name: Automated Test Suite

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test Suite to Run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - ui
          - api
          - specific
      test_file:
        description: 'Specific Test File (e.g., org.automation.ui.BlazeDemoTests)'
        required: false
        type: string
      test_method:
        description: 'Specific Test Method (e.g., testHomePageTitle)'
        required: false
        type: string
      browser:
        description: 'Browser for UI Tests'
        required: false
        default: 'chrome'
        type: choice
        options:
          - chrome
          - firefox
      generate_reports:
        description: 'Generate Reports'
        required: false
        default: true
        type: boolean

# Cancel older runs on same ref to save minutes
concurrency:
  group: regression-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  checks: write
  actions: read
  pull-requests: write

env:
  MAVEN_OPTS: -Xmx2048m -XX:+UseG1GC -Djava.awt.headless=true
  JAVA_VERSION: '17'
  DB_DATABASE: automation_tests
  DB_USER: root
  DB_PASSWORD: rooT@12345
  CI: true

jobs:
  setup:
    name: 🔧 Setup & Configuration
    runs-on: ubuntu-latest
    outputs:
      test-suites: ${{ steps.determine-suites.outputs.suites }}
      timestamp: ${{ steps.timestamp.outputs.timestamp }}
      test-file: ${{ steps.determine-suites.outputs.testfile }}
      test-method: ${{ steps.determine-suites.outputs.testmethod }}
      skip-ci: ${{ steps.check-commit.outputs.skip }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check for automation commits
        id: check-commit
        run: |
          if [[ "${{ github.event.head_commit.message }}" =~ ^(automation|auto|ci|build):.* ]]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "Skipping automation commit: ${{ github.event.head_commit.message }}"
          else
            echo "skip=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate Timestamp
        id: timestamp
        run: echo "timestamp=$(date +'%Y%m%d_%H%M%S')" >> $GITHUB_OUTPUT

      - name: Determine Test Suites
        id: determine-suites
        run: |
          if [ "${{ github.event.inputs.test_suite }}" == "specific" ]; then
            echo "suites=[\"specific\"]" >> $GITHUB_OUTPUT
            echo "testfile=${{ github.event.inputs.test_file }}" >> $GITHUB_OUTPUT
            echo "testmethod=${{ github.event.inputs.test_method }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.inputs.test_suite }}" == "ui" ]; then
            echo "suites=[\"ui\"]" >> $GITHUB_OUTPUT
            echo "testfile=" >> $GITHUB_OUTPUT
            echo "testmethod=" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.inputs.test_suite }}" == "api" ]; then
            echo "suites=[\"api\"]" >> $GITHUB_OUTPUT
            echo "testfile=" >> $GITHUB_OUTPUT
            echo "testmethod=" >> $GITHUB_OUTPUT
          else
            echo "suites=[\"ui\", \"api\"]" >> $GITHUB_OUTPUT
            echo "testfile=" >> $GITHUB_OUTPUT
            echo "testmethod=" >> $GITHUB_OUTPUT
          fi

      - name: Exit if automation commit
        if: steps.check-commit.outputs.skip == 'true'
        run: |
          echo "Skipping CI for automation commit"
          exit 78

  api-tests:
    name: 🧪 API Tests
    needs: setup
    if: needs.setup.outputs.skip-ci != 'true' && contains(fromJson(needs.setup.outputs.test-suites), 'api')
    runs-on: ubuntu-latest
    timeout-minutes: 30

    services:
      mysql:
        image: mysql:8.0
        ports: [ "3306:3306" ]
        env:
          MYSQL_ROOT_PASSWORD: ${{ env.DB_PASSWORD }}
          MYSQL_DATABASE: ${{ env.DB_DATABASE }}
        options: >-
          --health-cmd="mysqladmin ping -h localhost"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: maven

      - name: Print Maven & Java versions
        run: |
          java -version
          mvn -v

      - name: Wait for MySQL
        run: |
          for i in {1..30}; do
            if mysqladmin ping -h"127.0.0.1" -P3306 -u${{ env.DB_USER }} -p"${{ env.DB_PASSWORD }}" --silent; then
              echo "MySQL is ready!"
              break
            fi
            echo "Waiting for MySQL... ($i/30)"
            sleep 2
          done

      - name: Initialize Database Schema
        run: |
          mysql -h127.0.0.1 -u${{ env.DB_USER }} -p"${{ env.DB_PASSWORD }}" -e "
          CREATE DATABASE IF NOT EXISTS ${DB_DATABASE};
          USE ${DB_DATABASE};
          CREATE TABLE IF NOT EXISTS execution_log (
            id INT AUTO_INCREMENT PRIMARY KEY,
            test_name VARCHAR(255),
            status VARCHAR(20),
            test_type VARCHAR(20),
            us_id VARCHAR(50),
            tc_id VARCHAR(255),
            artifact VARCHAR(500),
            screenshot_path VARCHAR(500),
            execution_time DATETIME DEFAULT CURRENT_TIMESTAMP
          );"

      - name: Create Required Directories
        run: |
          mkdir -p artifacts/api
          mkdir -p artifacts/reports
          mkdir -p target/surefire-reports
          mkdir -p test-output

      - name: 📦 Cache Maven Dependencies
        uses: actions/cache@v3
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-

      - name: 🔨 Build Project
        run: mvn clean install -DskipTests

      - name: ▶️ Run API Tests (Parallel)
        run: |
          mvn test -Dtest=**/*JsonPlaceholderTests.java \
            -DthreadCount=10 \
            -Ddataproviderthreadcount=10 \
            -Dmaven.test.failure.ignore=true
        env:
          DB_URL: jdbc:mysql://127.0.0.1:3306/${{ env.DB_DATABASE }}
          DB_USERNAME: ${{ env.DB_USER }}
          DB_PASSWORD: ${{ env.DB_PASSWORD }}

      - name: 📦 Upload API Test Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: api-test-results-${{ needs.setup.outputs.timestamp }}
          path: |
            artifacts/api/
            artifacts/reports/
            target/surefire-reports/
            test-output/
          retention-days: 30

      - name: Publish JUnit (API)
        if: always()
        uses: dorny/test-reporter@v1
        with:
          name: API Tests
          path: target/surefire-reports/TEST-*.xml
          reporter: java-junit

  ui-tests:
    name: 🌐 UI Tests
    needs: setup
    if: needs.setup.outputs.skip-ci != 'true' && contains(fromJson(needs.setup.outputs.test-suites), 'ui')
    runs-on: ubuntu-latest
    timeout-minutes: 45

    services:
      mysql:
        image: mysql:8.0
        ports: [ "3306:3306" ]
        env:
          MYSQL_ROOT_PASSWORD: ${{ env.DB_PASSWORD }}
          MYSQL_DATABASE: ${{ env.DB_DATABASE }}
        options: >-
          --health-cmd="mysqladmin ping -h localhost"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10

    strategy:
      matrix:
        browser: [chrome]
      fail-fast: false

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: maven

      - name: Print Maven & Java versions
        run: |
          java -version
          mvn -v

      - name: Wait for MySQL
        run: |
          for i in {1..30}; do
            if mysqladmin ping -h"127.0.0.1" -P3306 -u${{ env.DB_USER }} -p"${{ env.DB_PASSWORD }}" --silent; then
              echo "MySQL is ready!"
              break
            fi
            echo "Waiting for MySQL... ($i/30)"
            sleep 2
          done

      - name: Initialize Database Schema
        run: |
          mysql -h127.0.0.1 -u${{ env.DB_USER }} -p"${{ env.DB_PASSWORD }}" -e "
          CREATE DATABASE IF NOT EXISTS ${DB_DATABASE};
          USE ${DB_DATABASE};
          CREATE TABLE IF NOT EXISTS execution_log (
            id INT AUTO_INCREMENT PRIMARY KEY,
            test_name VARCHAR(255),
            status VARCHAR(20),
            test_type VARCHAR(20),
            us_id VARCHAR(50),
            tc_id VARCHAR(255),
            artifact VARCHAR(500),
            screenshot_path VARCHAR(500),
            execution_time DATETIME DEFAULT CURRENT_TIMESTAMP
          );"

      - name: Setup Chrome
        if: matrix.browser == 'chrome' || github.event.inputs.browser == 'chrome'
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: stable

      - name: Setup Firefox
        if: matrix.browser == 'firefox' || github.event.inputs.browser == 'firefox'
        uses: browser-actions/setup-firefox@latest
        with:
          firefox-version: latest

      - name: Show Browser Version
        run: |
          google-chrome --version || chrome --version || firefox --version || echo "Browser version check"

      - name: Configure Git User
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"

      - name: Create Required Directories
        run: |
          mkdir -p artifacts/screenshots
          mkdir -p artifacts/reports
          mkdir -p target/surefire-reports
          mkdir -p target/screenshots
          mkdir -p test-output

      - name: Resolve & Cache Dependencies
        run: mvn -B -q dependency:go-offline

      - name: Run UI Tests (Headless)
        run: |
          export DISPLAY=:99
          Xvfb :99 -screen 0 1920x1080x24 &
          sleep 3
          
          mvn -B clean test \
            -DsuiteXmlFile=testng-ui.xml \
            -Dbrowser=${{ matrix.browser }} \
            -Dheadless=true \
            -Dparallel=methods \
            -DthreadCount=6 \
            -Ddataproviderthreadcount=6 \
            -Dmaven.test.failure.ignore=true
        env:
          BROWSER: ${{ matrix.browser }}
          HEADLESS: true
          SCREENSHOT_ON_FAILURE: true
          DB_URL: jdbc:mysql://127.0.0.1:3306/${{ env.DB_DATABASE }}
          DB_USERNAME: ${{ env.DB_USER }}
          DB_PASSWORD: ${{ env.DB_PASSWORD }}

      - name: Generate UI Test Reports
        if: always()
        run: |
          echo "Generating Surefire reports..."
          mvn surefire-report:report-only || true
          mvn site -DgenerateReports=false || true

      - name: Create Report Summary
        if: always()
        run: |
          mkdir -p artifacts/reports
          echo "# UI Test Report - ${{ matrix.browser }} - ${{ needs.setup.outputs.timestamp }}" > artifacts/reports/ui-summary-${{ matrix.browser }}.md
          echo "" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md
          echo "**Browser:** ${{ matrix.browser }}" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md
          echo "**Execution Time:** $(date)" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md
          echo "**Branch:** ${{ github.ref_name }}" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md
          echo "**Commit:** ${{ github.sha }}" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md
          echo "" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md
          
          if [ -f "test-output/testng-results.xml" ]; then
            echo "**Test Results:**" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md
            echo "\`\`\`" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md
            grep -oP 'total="\K[0-9]+' test-output/testng-results.xml | head -1 | xargs -I {} echo "Total: {}" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md || true
            grep -oP 'passed="\K[0-9]+' test-output/testng-results.xml | head -1 | xargs -I {} echo "Passed: {}" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md || true
            grep -oP 'failed="\K[0-9]+' test-output/testng-results.xml | head -1 | xargs -I {} echo "Failed: {}" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md || true
            grep -oP 'skipped="\K[0-9]+' test-output/testng-results.xml | head -1 | xargs -I {} echo "Skipped: {}" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md || true
            echo "\`\`\`" >> artifacts/reports/ui-summary-${{ matrix.browser }}.md
          fi

      - name: Upload UI Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ui-test-results-${{ matrix.browser }}-${{ needs.setup.outputs.timestamp }}
          path: |
            target/surefire-reports/
            target/site/
            artifacts/screenshots/
            artifacts/reports/
            target/screenshots/
            test-output/
          retention-days: 30

      - name: Upload Screenshots on Failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: ui-screenshots-failure-${{ matrix.browser }}-${{ needs.setup.outputs.timestamp }}
          path: |
            artifacts/screenshots/
            target/screenshots/
          retention-days: 7

      - name: Publish JUnit (UI)
        if: always()
        uses: dorny/test-reporter@v1
        with:
          name: UI Tests - ${{ matrix.browser }}
          path: target/surefire-reports/TEST-*.xml
          reporter: java-junit

  specific-test:
    name: 🎯 Specific Test
    needs: setup
    if: needs.setup.outputs.skip-ci != 'true' && contains(fromJson(needs.setup.outputs.test-suites), 'specific')
    runs-on: ubuntu-latest
    timeout-minutes: 30

    services:
      mysql:
        image: mysql:8.0
        ports: [ "3306:3306" ]
        env:
          MYSQL_ROOT_PASSWORD: ${{ env.DB_PASSWORD }}
          MYSQL_DATABASE: ${{ env.DB_DATABASE }}
        options: >-
          --health-cmd="mysqladmin ping -h localhost"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: maven

      - name: Wait for MySQL
        run: |
          for i in {1..30}; do
            if mysqladmin ping -h"127.0.0.1" -P3306 -u${{ env.DB_USER }} -p"${{ env.DB_PASSWORD }}" --silent; then
              echo "MySQL is ready!"
              break
            fi
            echo "Waiting for MySQL... ($i/30)"
            sleep 2
          done

      - name: Initialize Database Schema
        run: |
          mysql -h127.0.0.1 -u${{ env.DB_USER }} -p"${{ env.DB_PASSWORD }}" -e "
          CREATE DATABASE IF NOT EXISTS ${DB_DATABASE};
          USE ${DB_DATABASE};
          CREATE TABLE IF NOT EXISTS execution_log (
            id INT AUTO_INCREMENT PRIMARY KEY,
            test_name VARCHAR(255),
            status VARCHAR(20),
            test_type VARCHAR(20),
            us_id VARCHAR(50),
            tc_id VARCHAR(255),
            artifact VARCHAR(500),
            screenshot_path VARCHAR(500),
            execution_time DATETIME DEFAULT CURRENT_TIMESTAMP
          );"

      - name: Setup Chrome (default for specific tests)
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: stable

      - name: Configure Git User
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"

      - name: Create Required Directories
        run: |
          mkdir -p artifacts/screenshots
          mkdir -p artifacts/reports
          mkdir -p target/surefire-reports
          mkdir -p test-output

      - name: Resolve & Cache Dependencies
        run: mvn -B -q dependency:go-offline

      - name: Run Specific Test
        run: |
          TEST_CLASS="${{ needs.setup.outputs.test-file }}"
          TEST_METHOD="${{ needs.setup.outputs.test-method }}"
          
          if [ -z "$TEST_CLASS" ]; then
            echo "Error: No test class specified"
            exit 1
          fi
          
          export DISPLAY=:99
          Xvfb :99 -screen 0 1920x1080x24 &
          sleep 3
          
          if [ -n "$TEST_METHOD" ]; then
            echo "Running specific test method: $TEST_CLASS#$TEST_METHOD"
            mvn -B clean test \
              -Dtest="$TEST_CLASS#$TEST_METHOD" \
              -Dbrowser=${{ github.event.inputs.browser || 'chrome' }} \
              -Dheadless=true \
              -Dmaven.test.failure.ignore=true
          else
            echo "Running entire test class: $TEST_CLASS"
            mvn -B clean test \
              -Dtest="$TEST_CLASS" \
              -Dbrowser=${{ github.event.inputs.browser || 'chrome' }} \
              -Dheadless=true \
              -Dmaven.test.failure.ignore=true
          fi
        env:
          BROWSER: ${{ github.event.inputs.browser || 'chrome' }}
          HEADLESS: true
          SCREENSHOT_ON_FAILURE: true
          DB_URL: jdbc:mysql://127.0.0.1:3306/${{ env.DB_DATABASE }}
          DB_USERNAME: ${{ env.DB_USER }}
          DB_PASSWORD: ${{ env.DB_PASSWORD }}

      - name: Generate Test Reports
        if: always()
        run: |
          echo "Generating Surefire reports..."
          mvn surefire-report:report-only || true
          mvn site -DgenerateReports=false || true

      - name: Create Report Summary
        if: always()
        run: |
          mkdir -p artifacts/reports
          echo "# Specific Test Report - ${{ needs.setup.outputs.timestamp }}" > artifacts/reports/specific-test-summary.md
          echo "" >> artifacts/reports/specific-test-summary.md
          echo "**Test Class:** ${{ needs.setup.outputs.test-file }}" >> artifacts/reports/specific-test-summary.md
          echo "**Test Method:** ${{ needs.setup.outputs.test-method || 'All methods' }}" >> artifacts/reports/specific-test-summary.md
          echo "**Browser:** ${{ github.event.inputs.browser || 'chrome' }}" >> artifacts/reports/specific-test-summary.md
          echo "**Execution Time:** $(date)" >> artifacts/reports/specific-test-summary.md
          echo "**Branch:** ${{ github.ref_name }}" >> artifacts/reports/specific-test-summary.md
          echo "**Commit:** ${{ github.sha }}" >> artifacts/reports/specific-test-summary.md

      - name: Upload Specific Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: specific-test-results-${{ needs.setup.outputs.timestamp }}
          path: |
            target/surefire-reports/
            target/site/
            artifacts/screenshots/
            artifacts/reports/
            test-output/
          retention-days: 30

  consolidate-reports:
    name: 📊 Consolidate Reports
    needs: [setup, ui-tests, api-tests, specific-test]
    if: always() && needs.setup.outputs.skip-ci != 'true' && (needs.ui-tests.result != 'cancelled' || needs.api-tests.result != 'cancelled' || needs.specific-test.result != 'cancelled')
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download All Test Results
        uses: actions/download-artifact@v4
        with:
          path: all-results/

      - name: Consolidate Reports
        run: |
          mkdir -p consolidated-reports/{html,xml,json,screenshots}
          
          # Copy HTML reports
          find all-results/ -name "*.html" -exec cp {} consolidated-reports/html/ \; 2>/dev/null || true
          
          # Copy XML reports
          find all-results/ -name "*.xml" -exec cp {} consolidated-reports/xml/ \; 2>/dev/null || true
          
          # Copy JSON reports (API artifacts)
          find all-results/ -name "*.json" -exec cp {} consolidated-reports/json/ \; 2>/dev/null || true
          
          # Copy screenshots
          find all-results/ -type f \( -name "*.png" -o -name "*.jpg" \) -exec cp {} consolidated-reports/screenshots/ \; 2>/dev/null || true
          
          # Create summary report
          cat > consolidated-reports/README.md << EOF
          # Test Execution Summary - ${{ needs.setup.outputs.timestamp }}
          
          ## Execution Details
          - **Trigger:** ${{ github.event_name }}
          - **Branch:** ${{ github.ref_name }}
          - **Commit:** ${{ github.sha }}
          - **Timestamp:** $(date)
          
          ## Test Results
          - **UI Tests:** ${{ needs.ui-tests.result || 'N/A' }}
          - **API Tests:** ${{ needs.api-tests.result || 'N/A' }}
          - **Specific Test:** ${{ needs.specific-test.result || 'N/A' }}
          
          ## Report Structure
          - \`html/\` - HTML test reports (TestNG, Surefire)
          - \`xml/\` - XML test results (TestNG/JUnit)
          - \`json/\` - JSON test data (API responses)
          - \`screenshots/\` - Test failure screenshots
          
          ## Test Classes
          - **UI Tests:** org.automation.ui.BlazeDemoTests
          - **API Tests:** org.automation.api.JsonPlaceholderTests
          
          ## Access Reports
          1. Download artifacts from GitHub Actions
          2. View TestNG reports in \`html/\` directory
          3. Check screenshots in \`screenshots/\` directory
          EOF
          
          echo "Report consolidation complete!"
          ls -la consolidated-reports/

      - name: Parse Test Results Summary
        id: parse-results
        run: |
          TOTAL=0
          PASSED=0
          FAILED=0
          SKIPPED=0
          
          for file in $(find all-results -name "testng-results.xml" 2>/dev/null); do
            if [ -f "$file" ]; then
              echo "Parsing: $file"
              TESTS=$(grep -oP 'total="\K[0-9]+' "$file" | head -1 || echo "0")
              PASS=$(grep -oP 'passed="\K[0-9]+' "$file" | head -1 || echo "0")
              FAIL=$(grep -oP 'failed="\K[0-9]+' "$file" | head -1 || echo "0")
              SKIP=$(grep -oP 'skipped="\K[0-9]+' "$file" | head -1 || echo "0")
              
              TOTAL=$((TOTAL + TESTS))
              PASSED=$((PASSED + PASS))
              FAILED=$((FAILED + FAIL))
              SKIPPED=$((SKIPPED + SKIP))
            fi
          done
          
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "skipped=$SKIPPED" >> $GITHUB_OUTPUT
          
          # Create visual summary
          cat >> consolidated-reports/README.md << EOF
          
          ## Statistics
          - **Total Tests:** $TOTAL
          - **Passed:** $PASSED ✅
          - **Failed:** $FAILED ❌
          - **Skipped:** $SKIPPED ⏭️
          - **Pass Rate:** $(awk "BEGIN {printf \"%.2f\", ($PASSED/$TOTAL)*100}")%
          EOF

      - name: Upload Consolidated Reports
        uses: actions/upload-artifact@v4
        with:
          name: consolidated-test-reports-${{ needs.setup.outputs.timestamp }}
          path: consolidated-reports/
          retention-days: 90

      - name: Generate Job Summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY << EOF
          # 📊 Test Execution Summary
          
          ## 🎯 Results
          | Suite | Status | 
          |-------|--------|
          | UI Tests | ${{ needs.ui-tests.result || 'N/A' }} |
          | API Tests | ${{ needs.api-tests.result || 'N/A' }} |
          | Specific Test | ${{ needs.specific-test.result || 'N/A' }} |
          
          ## 📈 Statistics
          - **Total Tests:** ${{ steps.parse-results.outputs.total }}
          - **Passed:** ${{ steps.parse-results.outputs.passed }} ✅
          - **Failed:** ${{ steps.parse-results.outputs.failed }} ❌
          - **Skipped:** ${{ steps.parse-results.outputs.skipped }} ⏭️
          
          ## 🔗 Artifacts
          - Consolidated reports available in workflow artifacts
          - Timestamp: ${{ needs.setup.outputs.timestamp }}
          EOF

  notification:
    name: 📢 Notification
    needs: [setup, ui-tests, api-tests, specific-test, consolidate-reports]
    if: always() && needs.setup.outputs.skip-ci != 'true'
    runs-on: ubuntu-latest

    steps:
      - name: Notify on Failure
        if: needs.ui-tests.result == 'failure' || needs.api-tests.result == 'failure' || needs.specific-test.result == 'failure'
        run: |
          echo "⚠️ Tests failed! Check the artifacts for detailed reports."
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "UI Tests: ${{ needs.ui-tests.result }}"
          echo "API Tests: ${{ needs.api-tests.result }}"
          echo "Specific Test: ${{ needs.specific-test.result }}"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "📊 Download consolidated reports from artifacts"
          echo "🔍 Check screenshots for UI test failures"

      - name: Notify on Success
        if: (needs.ui-tests.result == 'success' || needs.ui-tests.result == 'skipped') && (needs.api-tests.result == 'success' || needs.api-tests.result == 'skipped') && (needs.specific-test.result == 'success' || needs.specific-test.result == 'skipped')
        run: |
          echo "✅ All tests passed successfully!"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "UI Tests: ${{ needs.ui-tests.result }}"
          echo "API Tests: ${{ needs.api-tests.result }}"
          echo "Specific Test: ${{ needs.specific-test.result }}"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "📊 Consolidated reports generated"
          echo "✨ All test suites completed successfully"
